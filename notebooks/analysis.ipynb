{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä Customer Purchase Behavior Analysis\n",
        "\n",
        "## Interactive Analysis with PySpark\n",
        "\n",
        "This notebook provides an interactive environment for exploring customer purchase behavior using PySpark and the Online Retail Dataset.\n",
        "\n",
        "### üìã Table of Contents\n",
        "1. [Setup and Data Loading](#setup)\n",
        "2. [Data Exploration](#exploration)\n",
        "3. [Customer Analysis](#customers)\n",
        "4. [Product Analysis](#products)\n",
        "5. [Temporal Patterns](#temporal)\n",
        "6. [Geographic Analysis](#geographic)\n",
        "7. [Visualizations](#visualizations)\n",
        "8. [Key Insights](#insights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Setup and Data Loading <a id=\"setup\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üì¶ Libraries imported successfully!\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Add project root to path\n",
        "project_root = Path.cwd().parent\n",
        "sys.path.append(str(project_root))\n",
        "\n",
        "# Import PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "\n",
        "# Import visualization libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Import project modules\n",
        "from src.data_ingestion import create_spark_session\n",
        "from src.data_analysis import CustomerPurchaseAnalyzer\n",
        "from src.visualization import AnalysisVisualizer\n",
        "from config import PROCESSED_DATA_DIR, CHARTS_DIR\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette('Set2')\n",
        "%matplotlib inline\n",
        "\n",
        "print(\"üì¶ Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-08-22 13:55:58,269 - INFO - Spark session created successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Spark session created: CustomerPurchaseBehaviorAnalysis\n",
            "üîß Spark version: 3.5.0\n",
            "üíª Master: local[*]\n"
          ]
        }
      ],
      "source": [
        "# Create Spark Session\n",
        "spark = create_spark_session()\n",
        "print(f\"‚úÖ Spark session created: {spark.sparkContext.appName}\")\n",
        "print(f\"üîß Spark version: {spark.version}\")\n",
        "print(f\"üíª Master: {spark.sparkContext.master}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ùå Processed data not found. Please run the data ingestion script first.\n",
            "Run: python src/data_ingestion.py\n"
          ]
        }
      ],
      "source": [
        "# Load processed data\n",
        "processed_data_path = PROCESSED_DATA_DIR / \"retail_data_processed.parquet\"\n",
        "\n",
        "if processed_data_path.exists():\n",
        "    df = spark.read.parquet(str(processed_data_path))\n",
        "    print(f\"‚úÖ Data loaded from: {processed_data_path}\")\n",
        "    print(f\"üìä Dataset shape: {df.count()} rows, {len(df.columns)} columns\")\n",
        "else:\n",
        "    print(\"‚ùå Processed data not found. Please run the data ingestion script first.\")\n",
        "    print(\"Run: python src/data_ingestion.py\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Data Exploration <a id=\"exploration\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Dataset Schema:\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Display basic information about the dataset\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìã Dataset Schema:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdf\u001b[49m.printSchema()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33müìà Dataset Statistics:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal Records: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf.count()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# Display basic information about the dataset\n",
        "print(\"üìã Dataset Schema:\")\n",
        "df.printSchema()\n",
        "\n",
        "print(\"\\nüìà Dataset Statistics:\")\n",
        "print(f\"Total Records: {df.count():,}\")\n",
        "print(f\"Unique Customers: {df.select('CustomerID').distinct().count():,}\")\n",
        "print(f\"Unique Products: {df.select('StockCode').distinct().count():,}\")\n",
        "print(f\"Unique Countries: {df.select('Country').distinct().count():,}\")\n",
        "\n",
        "# Date range\n",
        "date_stats = df.select(\n",
        "    min('InvoiceDate').alias('earliest_date'),\n",
        "    max('InvoiceDate').alias('latest_date')\n",
        ").collect()[0]\n",
        "\n",
        "print(f\"Date Range: {date_stats.earliest_date} to {date_stats.latest_date}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "print(\"üîç Sample Data:\")\n",
        "df.select('InvoiceNo', 'Description', 'Quantity', 'UnitPrice', 'TotalAmount', 'Country').show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick statistics on numerical columns\n",
        "print(\"üìä Numerical Statistics:\")\n",
        "df.select('Quantity', 'UnitPrice', 'TotalAmount').describe().show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üë• Customer Analysis <a id=\"customers\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Customer spending analysis\n",
        "customer_stats = df.groupBy('CustomerID') \\\n",
        "                  .agg(\n",
        "                      sum('TotalAmount').alias('total_spent'),\n",
        "                      count('InvoiceNo').alias('order_count'),\n",
        "                      countDistinct('StockCode').alias('unique_products'),\n",
        "                      avg('TotalAmount').alias('avg_order_value')\n",
        "                  ) \\\n",
        "                  .orderBy(desc('total_spent'))\n",
        "\n",
        "print(\"üí∞ Top 10 Customers by Spending:\")\n",
        "customer_stats.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Customer segmentation\n",
        "customer_segments = customer_stats.withColumn('segment',\n",
        "    when(col('total_spent') >= 1000, 'High Value')\n",
        "    .when(col('total_spent') >= 100, 'Medium Value')\n",
        "    .otherwise('Low Value')\n",
        ")\n",
        "\n",
        "segment_summary = customer_segments.groupBy('segment') \\\n",
        "                                 .agg(\n",
        "                                     count('*').alias('customer_count'),\n",
        "                                     avg('total_spent').alias('avg_spent'),\n",
        "                                     avg('order_count').alias('avg_orders')\n",
        "                                 )\n",
        "\n",
        "print(\"üìä Customer Segments:\")\n",
        "segment_summary.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üõçÔ∏è Product Analysis <a id=\"products\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top products by revenue\n",
        "top_products = df.groupBy('StockCode', 'Description') \\\n",
        "                .agg(\n",
        "                    sum('TotalAmount').alias('total_revenue'),\n",
        "                    sum('Quantity').alias('total_quantity'),\n",
        "                    count('*').alias('order_count')\n",
        "                ) \\\n",
        "                .orderBy(desc('total_revenue'))\n",
        "\n",
        "print(\"üèÜ Top 15 Products by Revenue:\")\n",
        "top_products.show(15, truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Product categories analysis (based on stock codes)\n",
        "df_with_category = df.withColumn('category', regexp_extract(col('StockCode'), '^([A-Z]+)', 1))\n",
        "df_with_category = df_with_category.filter(col('category') != '')\n",
        "\n",
        "category_analysis = df_with_category.groupBy('category') \\\n",
        "                                   .agg(\n",
        "                                       sum('TotalAmount').alias('total_revenue'),\n",
        "                                       sum('Quantity').alias('total_quantity'),\n",
        "                                       countDistinct('StockCode').alias('unique_products')\n",
        "                                   ) \\\n",
        "                                   .orderBy(desc('total_revenue'))\n",
        "\n",
        "print(\"üìÇ Product Categories by Revenue:\")\n",
        "category_analysis.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚è∞ Temporal Patterns <a id=\"temporal\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hourly sales pattern\n",
        "hourly_sales = df.groupBy('Hour') \\\n",
        "                .agg(\n",
        "                    sum('TotalAmount').alias('total_revenue'),\n",
        "                    count('*').alias('order_count')\n",
        "                ) \\\n",
        "                .orderBy('Hour')\n",
        "\n",
        "print(\"üïê Sales by Hour of Day:\")\n",
        "hourly_sales.show(24)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Daily sales pattern (day of week)\n",
        "daily_sales = df.groupBy('DayOfWeek', 'DayName') \\\n",
        "               .agg(\n",
        "                   sum('TotalAmount').alias('total_revenue'),\n",
        "                   count('*').alias('order_count')\n",
        "               ) \\\n",
        "               .orderBy('DayOfWeek')\n",
        "\n",
        "print(\"üìÖ Sales by Day of Week:\")\n",
        "daily_sales.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Monthly sales trend\n",
        "monthly_sales = df.groupBy('Year', 'Month') \\\n",
        "                 .agg(\n",
        "                     sum('TotalAmount').alias('total_revenue'),\n",
        "                     count('*').alias('order_count'),\n",
        "                     countDistinct('CustomerID').alias('unique_customers')\n",
        "                 ) \\\n",
        "                 .orderBy('Year', 'Month')\n",
        "\n",
        "print(\"üìà Monthly Sales Trend:\")\n",
        "monthly_sales.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üåç Geographic Analysis <a id=\"geographic\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sales by country\n",
        "country_analysis = df.groupBy('Country') \\\n",
        "                    .agg(\n",
        "                        sum('TotalAmount').alias('total_revenue'),\n",
        "                        count('*').alias('order_count'),\n",
        "                        countDistinct('CustomerID').alias('unique_customers'),\n",
        "                        avg('TotalAmount').alias('avg_order_value')\n",
        "                    ) \\\n",
        "                    .orderBy(desc('total_revenue'))\n",
        "\n",
        "print(\"üó∫Ô∏è Sales by Country:\")\n",
        "country_analysis.show(20, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualizations <a id=\"visualizations\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert Spark DataFrames to Pandas for plotting\n",
        "hourly_pd = hourly_sales.toPandas()\n",
        "daily_pd = daily_sales.toPandas().sort_values('DayOfWeek')\n",
        "top_products_pd = top_products.limit(15).toPandas()\n",
        "country_pd = country_analysis.limit(15).toPandas()\n",
        "\n",
        "print(\"‚úÖ Data converted to Pandas for visualization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hourly sales pattern\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(hourly_pd['Hour'], hourly_pd['total_revenue'], marker='o', linewidth=2)\n",
        "plt.title('Revenue by Hour of Day')\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Revenue ($)')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xticks(range(0, 24, 2))\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.bar(hourly_pd['Hour'], hourly_pd['order_count'], alpha=0.7)\n",
        "plt.title('Order Count by Hour of Day')\n",
        "plt.xlabel('Hour')\n",
        "plt.ylabel('Number of Orders')\n",
        "plt.xticks(range(0, 24, 2))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top products visualization\n",
        "plt.figure(figsize=(14, 10))\n",
        "top_10_products = top_products_pd.head(10)\n",
        "\n",
        "# Truncate long product names for better display\n",
        "product_names = [name[:30] + '...' if len(name) > 30 else name for name in top_10_products['Description']]\n",
        "\n",
        "plt.barh(range(len(top_10_products)), top_10_products['total_revenue'])\n",
        "plt.yticks(range(len(top_10_products)), product_names)\n",
        "plt.xlabel('Total Revenue ($)')\n",
        "plt.title('Top 10 Products by Revenue')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# Add value labels\n",
        "for i, v in enumerate(top_10_products['total_revenue']):\n",
        "    plt.text(v, i, f' ${v:,.0f}', va='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Geographic analysis\n",
        "plt.figure(figsize=(14, 8))\n",
        "top_countries = country_pd.head(10)\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.barh(range(len(top_countries)), top_countries['total_revenue'])\n",
        "plt.yticks(range(len(top_countries)), top_countries['Country'])\n",
        "plt.xlabel('Total Revenue ($)')\n",
        "plt.title('Top 10 Countries by Revenue')\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.bar(range(len(top_countries)), top_countries['unique_customers'])\n",
        "plt.xticks(range(len(top_countries)), top_countries['Country'], rotation=45, ha='right')\n",
        "plt.ylabel('Number of Customers')\n",
        "plt.title('Top 10 Countries by Customer Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive Plotly visualization\n",
        "fig = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('Hourly Sales Pattern', 'Daily Sales Pattern', \n",
        "                   'Top Products', 'Geographic Distribution'),\n",
        "    specs=[[{\"secondary_y\": True}, {}],\n",
        "           [{\"type\": \"bar\"}, {\"type\": \"bar\"}]]\n",
        ")\n",
        "\n",
        "# Hourly pattern\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=hourly_pd['Hour'], y=hourly_pd['total_revenue'], \n",
        "               mode='lines+markers', name='Revenue'),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Daily pattern\n",
        "fig.add_trace(\n",
        "    go.Bar(x=daily_pd['DayName'], y=daily_pd['total_revenue'], name='Daily Revenue'),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# Top products\n",
        "top_5_products = top_products_pd.head(5)\n",
        "fig.add_trace(\n",
        "    go.Bar(x=top_5_products['total_revenue'], \n",
        "           y=[name[:20] + '...' if len(name) > 20 else name for name in top_5_products['Description']],\n",
        "           orientation='h', name='Product Revenue'),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# Countries\n",
        "top_5_countries = country_pd.head(5)\n",
        "fig.add_trace(\n",
        "    go.Bar(x=top_5_countries['Country'], y=top_5_countries['total_revenue'], \n",
        "           name='Country Revenue'),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(height=800, showlegend=False, \n",
        "                 title_text=\"Customer Purchase Behavior Dashboard\")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí° Key Insights <a id=\"insights\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate key insights\n",
        "total_revenue = df.agg(sum('TotalAmount')).collect()[0][0]\n",
        "total_orders = df.count()\n",
        "unique_customers = df.select('CustomerID').distinct().count()\n",
        "unique_products = df.select('StockCode').distinct().count()\n",
        "avg_order_value = df.agg(avg('TotalAmount')).collect()[0][0]\n",
        "\n",
        "# Peak shopping hours\n",
        "peak_hours = hourly_pd.nlargest(3, 'order_count')\n",
        "\n",
        "# Top spending customer\n",
        "top_customer_spending = customer_stats.first()['total_spent']\n",
        "\n",
        "print(\"üéØ KEY BUSINESS INSIGHTS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üí∞ Total Revenue: ${total_revenue:,.2f}\")\n",
        "print(f\"üõí Total Orders: {total_orders:,}\")\n",
        "print(f\"üë• Unique Customers: {unique_customers:,}\")\n",
        "print(f\"üì¶ Unique Products: {unique_products:,}\")\n",
        "print(f\"üí≥ Average Order Value: ${avg_order_value:.2f}\")\n",
        "print(f\"üîÑ Orders per Customer: {total_orders/unique_customers:.1f}\")\n",
        "print(f\"üíé Top Customer Spent: ${top_customer_spending:,.2f}\")\n",
        "\n",
        "print(\"\\n‚è∞ PEAK SHOPPING HOURS:\")\n",
        "for _, hour_data in peak_hours.iterrows():\n",
        "    print(f\"   {hour_data['Hour']:02d}:00 - {hour_data['order_count']:,} orders\")\n",
        "\n",
        "print(\"\\nüèÜ TOP PERFORMING PRODUCT:\")\n",
        "top_product = top_products_pd.iloc[0]\n",
        "print(f\"   {top_product['Description']} - ${top_product['total_revenue']:,.2f}\")\n",
        "\n",
        "print(\"\\nüåç TOP MARKET:\")\n",
        "top_market = country_pd.iloc[0]\n",
        "print(f\"   {top_market['Country']} - ${top_market['total_revenue']:,.2f} ({top_market['unique_customers']:,} customers)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Business recommendations based on analysis\n",
        "print(\"üíº BUSINESS RECOMMENDATIONS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Find best day for marketing\n",
        "best_day = daily_pd.loc[daily_pd['total_revenue'].idxmax()]\n",
        "print(f\"üìÖ Focus marketing on {best_day['DayName']} (highest sales day)\")\n",
        "\n",
        "# Customer segmentation insight\n",
        "segment_pd = segment_summary.toPandas()\n",
        "high_value_pct = (segment_pd[segment_pd['segment'] == 'High Value']['customer_count'].iloc[0] / unique_customers * 100) if 'High Value' in segment_pd['segment'].values else 0\n",
        "print(f\"üëë {high_value_pct:.1f}% of customers are high-value - focus retention efforts here\")\n",
        "\n",
        "# Geographic expansion\n",
        "if len(country_pd) > 1:\n",
        "    second_market = country_pd.iloc[1]\n",
        "    revenue_gap = top_market['total_revenue'] - second_market['total_revenue']\n",
        "    print(f\"üåê Consider expanding in {second_market['Country']} (${revenue_gap:,.0f} growth potential)\")\n",
        "\n",
        "# Inventory optimization\n",
        "top_3_products = top_products_pd.head(3)\n",
        "print(f\"üì¶ Ensure stock availability for top 3 products (${top_3_products['total_revenue'].sum():,.0f} revenue)\")\n",
        "\n",
        "# Peak hour staffing\n",
        "peak_hour = peak_hours.iloc[0]['Hour']\n",
        "print(f\"üë®‚Äçüíº Optimize staffing around {peak_hour:02d}:00 (peak order time)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Stop Spark session when done\n",
        "spark.stop()\n",
        "print(\"‚úÖ Spark session stopped\")\n",
        "print(\"\\nüéâ Analysis complete! You can now:\")\n",
        "print(\"   1. Review the insights above\")\n",
        "print(\"   2. Run the main analysis script for full reports\")\n",
        "print(\"   3. Create additional custom visualizations\")\n",
        "print(\"   4. Export results for presentation\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
